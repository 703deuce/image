# RunPod Serverless Environment Variables Template
# Copy these values to your RunPod endpoint configuration

# Python optimization
PYTHONUNBUFFERED=1
PYTHONDONTWRITEBYTECODE=1

# Model caching (use RunPod volume for persistence)
HF_HOME=/runpod-volume/cache
TRANSFORMERS_CACHE=/runpod-volume/cache
DIFFUSERS_CACHE=/runpod-volume/cache

# GPU memory optimization
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
CUDA_LAUNCH_BLOCKING=0

# Optional: Hugging Face token for private models
# HF_TOKEN=your_hugging_face_token_here

# Optional: Performance optimizations
TOKENIZERS_PARALLELISM=false
OMP_NUM_THREADS=8