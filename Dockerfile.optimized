# Optimized Dockerfile for FLUX.1-dev RunPod API
FROM runpod/pytorch:2.1.0-py3.10-cuda12.1.1-devel-ubuntu22.04

# Set working directory
WORKDIR /app

# Set environment variables for optimization
ENV PYTHONUNBUFFERED=1
ENV PYTHONDONTWRITEBYTECODE=1
ENV HF_HOME=/app/cache
ENV TRANSFORMERS_CACHE=/app/cache  
ENV DIFFUSERS_CACHE=/app/cache
ENV PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512

# Create cache directories
RUN mkdir -p /app/cache /tmp/outputs

# Install system dependencies
RUN apt-get update && apt-get install -y \
    git \
    wget \
    curl \
    unzip \
    && rm -rf /var/lib/apt/lists/* \
    && apt-get clean

# Copy and install Python dependencies first (for better caching)
COPY requirements.txt .
RUN pip install --no-cache-dir --upgrade pip setuptools wheel
RUN pip install --no-cache-dir -r requirements.txt

# Install performance optimizations
RUN pip install --no-cache-dir ninja flash-attn --no-build-isolation || echo "Optional packages failed"

# Copy application code
COPY handler.py runpod_api.py ./

# Pre-download model (optional - increases image size but reduces cold start)
# Uncomment the next line to pre-download the model (adds ~24GB to image size)
# RUN python -c "import torch; from diffusers import FluxPipeline; FluxPipeline.from_pretrained('black-forest-labs/FLUX.1-dev', torch_dtype=torch.bfloat16)"

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD python -c "import torch; print('CUDA:', torch.cuda.is_available())" || exit 1

# Set default command
CMD ["python", "handler.py"]
